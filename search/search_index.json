{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Neuroscout? Neuroscout is an end-to-end platform for analysis of naturalistic fMRI data designed to facilitate the adoption of robust and generalizable research practices . Neuroscout leverages state-of-the-art machine learning models to automatically annotate naturalistic stimuli in dozens of naturalistic fMRI datasets , resulting in hundreds of potential neural predictors . We pair this with an easy-to-use analysis builder , enabling researchers to flexibly define novel statistical models. Analysis execution is achieved with no configuration using self-contained bundles tied to unique analysis IDs, and run-time data retrieval using DataLad . Containerized model-fitting pipelines minimize software dependencies and ensure high portability across execution environments. Finally, we make it easy for researchers to share their results with interactive reports and automatic upload of statistical images to NeuroVault . Neuroscout Docs The Analysis creation section serves as a step-by-step tutorial demonstrating how an analysis is created on the neuroscout website. Follow along through the sections sequentially to create an analysis or skip around for more information about sections of interest as needed. See Browse & manage for details on viewing and working with already generated analyses. For information about running analyses using containers or the command line interface, see the Run analyses section. Where can I get more help? In the analysis builder, be on the look out for informational tooltips (\"i\" icon), provided throughout to clarify aspects of the web interface. Also, please read the FAQ if you have questions. For additional help, please ask questions on NeuroStars . For bug reports and feature requests please open an issue on open an issue on GitHub . Reference Neuroscout, a unified platform for generalizable and reproducible fMRI research. Alejandro de la Vega, Roberta Rocca, Ross W. Blair, Christopher J. Markiewicz, Jeff Mentch, James D. Kent, Peer Herholz, Satrajit S. Ghosh, Russell A. Poldrack, Tal Yarkoni. bioRxiv 2022.04.05.487222; doi: https://doi.org/10.1101/2022.04.05.487222","title":"Home"},{"location":"#what-is-neuroscout","text":"Neuroscout is an end-to-end platform for analysis of naturalistic fMRI data designed to facilitate the adoption of robust and generalizable research practices . Neuroscout leverages state-of-the-art machine learning models to automatically annotate naturalistic stimuli in dozens of naturalistic fMRI datasets , resulting in hundreds of potential neural predictors . We pair this with an easy-to-use analysis builder , enabling researchers to flexibly define novel statistical models. Analysis execution is achieved with no configuration using self-contained bundles tied to unique analysis IDs, and run-time data retrieval using DataLad . Containerized model-fitting pipelines minimize software dependencies and ensure high portability across execution environments. Finally, we make it easy for researchers to share their results with interactive reports and automatic upload of statistical images to NeuroVault .","title":"What is Neuroscout?"},{"location":"#neuroscout-docs","text":"The Analysis creation section serves as a step-by-step tutorial demonstrating how an analysis is created on the neuroscout website. Follow along through the sections sequentially to create an analysis or skip around for more information about sections of interest as needed. See Browse & manage for details on viewing and working with already generated analyses. For information about running analyses using containers or the command line interface, see the Run analyses section.","title":"Neuroscout Docs"},{"location":"#where-can-i-get-more-help","text":"In the analysis builder, be on the look out for informational tooltips (\"i\" icon), provided throughout to clarify aspects of the web interface. Also, please read the FAQ if you have questions. For additional help, please ask questions on NeuroStars . For bug reports and feature requests please open an issue on open an issue on GitHub .","title":"Where can I get more help?"},{"location":"#reference","text":"Neuroscout, a unified platform for generalizable and reproducible fMRI research. Alejandro de la Vega, Roberta Rocca, Ross W. Blair, Christopher J. Markiewicz, Jeff Mentch, James D. Kent, Peer Herholz, Satrajit S. Ghosh, Russell A. Poldrack, Tal Yarkoni. bioRxiv 2022.04.05.487222; doi: https://doi.org/10.1101/2022.04.05.487222","title":"Reference"},{"location":"faq/","text":"Frequently Asked Questions Is this service free to use? Yes! Note, however, that Neuroscout is a web-based engine for fMRI analysis specification; at the moment, we don't provide free computing resources for the execution of the resulting analysis bundles. Analyses can be run on Google Colab and a demo notebook is provided here . I plan to publish results I've obtained using Neuroscout, how do I cite? After you generate an analysis, a \"Bibliography\" tab will be shown which will auto-generate a reference list for the dataset, feature extractors, and scientific software used for that analysis. In addition to these references, be sure to include the unique analysis ID associated with any results. Are there any restrictions on analyses I've created? Yes. By using Neuroscout, you agree that once you have finalized and \"compiled\" an analysis, the analysis can no longer be deleted from our system. If you wish to 'edit' an Analysis, you may clone the analysis, and make any desired changed on the forked version. Although analyses are by default not searchable by other users, any user with the private analysis ID may view your analysis. Also, in the event that you publish any results generated using the NeuroScout interface, you MUST provide a link to the corresponding analysis page(s) on the NeuroScout website. I have a naturalistic study I'd like to share on Neuroscout, how do I do so? Due to the financial cost of extracting features from multi-modal stimuli using external APIs, the set of datasets we support is manually curated. However, we are continually expanding the list of supported datasets, and we encourage researchers to contact us if they want to make their data available for use in Neuroscout. Note that it is much easier for us to ingest datasets that are already deposited in the OpenNeuro repository, and we we strongly recommend uploading your dataset to OpenNeuro whether or not it eventually ends up in Neuroscout. I want to make changes to an analysis I already ran, but it is locked. How can I edit it? Once an analysis has been run, it is permanently locked and archived for provenance. You may \"clone\" your analysis, and make changes to this new copy of your analysis. I want to make one of my \"private\" analyses public, but the website says the analysis is \"locked\"! When an analysis is locked, you can no longer make any substantive changes that affect model specification. However, you can always edit the name, description, and public/private status. So go ahead and make your analysis public! How do you automatically extract features from naturalistic datasets? The original stimuli presented to users are submitted to various machine learning algorithms and services to extract novel feature timecourses. To facility this process, we have developed a Python library for multimodal feature extraction called pliers. Pliers allows us to extract a wide-variety of features across modalities using various external content analysis services with ease. For example, we are able to use Google Vision API to encode various aspects of the visual elements of movie frames, such as when a face is present. In addition, pliers allows us to easily link up various feature extraction services; for example, we can use the IBM Watson Speech to Text API to transcribe the speech in a movie into words with precise onsets, and then use a predefined dictionary of lexical norms to extract lexical norms for each word, such as frequency. We can then generate timecourses for each of these extracted features, creating novel predictors of brain activity. For more information of pliers, please see the GitHub repository and the following paper: McNamara, Q., De La Vega, A., & Yarkoni, T. (2017, August). Developing a comprehensive framework for multimodal feature extraction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1567-1574). ACM. Am I restricted to mass univariate GLMs, or can I use Neuroscout to specify other kinds of analyses? Currently, that is the case. However,the underlying BIDS-StatsModel is designed with more complex models in mind, such as predictive and linear-mixed effect models Can I contribute my own predictors to Neuroscout? Yes! Using the \"My Predictors\" function, you can create custom collections of predictors to add to your analyses. Simply navigate to My Predictors , and click on \"Add New Predictors\". Features should be in BIDS-compliant events format. Two columns are mandatory: \"onset\" and \"duration\" (both in seconds). You can then include any number of novel predictors as additional columns. Missing values can be annotated using the value \"n/a\" (no quotes). For each events file that you upload, you will be asked to associate it with runs in the respective dataset. Typically, there will be a different event file for each run in a naturalistic dataset. You must then associate each file with subjects. For example, in most cases, all subjects will have seen the same stimulus, but this will vary across datasets. After uploading, a new collection of predictors will be created. By default, predictors in this collection will be private, and only visible to you in the Analysis Builder. If you wish to share these predictors with other Neuroscout users, please contact us, and we can make your predictors public.","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#is-this-service-free-to-use","text":"Yes! Note, however, that Neuroscout is a web-based engine for fMRI analysis specification; at the moment, we don't provide free computing resources for the execution of the resulting analysis bundles. Analyses can be run on Google Colab and a demo notebook is provided here .","title":"Is this service free to use?"},{"location":"faq/#i-plan-to-publish-results-ive-obtained-using-neuroscout-how-do-i-cite","text":"After you generate an analysis, a \"Bibliography\" tab will be shown which will auto-generate a reference list for the dataset, feature extractors, and scientific software used for that analysis. In addition to these references, be sure to include the unique analysis ID associated with any results.","title":"I plan to publish results I've obtained using Neuroscout, how do I cite?"},{"location":"faq/#are-there-any-restrictions-on-analyses-ive-created","text":"Yes. By using Neuroscout, you agree that once you have finalized and \"compiled\" an analysis, the analysis can no longer be deleted from our system. If you wish to 'edit' an Analysis, you may clone the analysis, and make any desired changed on the forked version. Although analyses are by default not searchable by other users, any user with the private analysis ID may view your analysis. Also, in the event that you publish any results generated using the NeuroScout interface, you MUST provide a link to the corresponding analysis page(s) on the NeuroScout website.","title":"Are there any restrictions on analyses I've created?"},{"location":"faq/#i-have-a-naturalistic-study-id-like-to-share-on-neuroscout-how-do-i-do-so","text":"Due to the financial cost of extracting features from multi-modal stimuli using external APIs, the set of datasets we support is manually curated. However, we are continually expanding the list of supported datasets, and we encourage researchers to contact us if they want to make their data available for use in Neuroscout. Note that it is much easier for us to ingest datasets that are already deposited in the OpenNeuro repository, and we we strongly recommend uploading your dataset to OpenNeuro whether or not it eventually ends up in Neuroscout.","title":"I have a naturalistic study I'd like to share on Neuroscout, how do I do so?"},{"location":"faq/#i-want-to-make-changes-to-an-analysis-i-already-ran-but-it-is-locked-how-can-i-edit-it","text":"Once an analysis has been run, it is permanently locked and archived for provenance. You may \"clone\" your analysis, and make changes to this new copy of your analysis.","title":"I want to make changes to an analysis I already ran, but it is locked. How can I edit it?"},{"location":"faq/#i-want-to-make-one-of-my-private-analyses-public-but-the-website-says-the-analysis-is-locked","text":"When an analysis is locked, you can no longer make any substantive changes that affect model specification. However, you can always edit the name, description, and public/private status. So go ahead and make your analysis public!","title":"I want to make one of my \"private\" analyses public, but the website says the analysis is \"locked\"!"},{"location":"faq/#how-do-you-automatically-extract-features-from-naturalistic-datasets","text":"The original stimuli presented to users are submitted to various machine learning algorithms and services to extract novel feature timecourses. To facility this process, we have developed a Python library for multimodal feature extraction called pliers. Pliers allows us to extract a wide-variety of features across modalities using various external content analysis services with ease. For example, we are able to use Google Vision API to encode various aspects of the visual elements of movie frames, such as when a face is present. In addition, pliers allows us to easily link up various feature extraction services; for example, we can use the IBM Watson Speech to Text API to transcribe the speech in a movie into words with precise onsets, and then use a predefined dictionary of lexical norms to extract lexical norms for each word, such as frequency. We can then generate timecourses for each of these extracted features, creating novel predictors of brain activity. For more information of pliers, please see the GitHub repository and the following paper: McNamara, Q., De La Vega, A., & Yarkoni, T. (2017, August). Developing a comprehensive framework for multimodal feature extraction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1567-1574). ACM.","title":"How do you automatically extract features from naturalistic datasets?"},{"location":"faq/#am-i-restricted-to-mass-univariate-glms-or-can-i-use-neuroscout-to-specify-other-kinds-of-analyses","text":"Currently, that is the case. However,the underlying BIDS-StatsModel is designed with more complex models in mind, such as predictive and linear-mixed effect models","title":"Am I restricted to mass univariate GLMs, or can I use Neuroscout to specify other kinds of analyses?"},{"location":"faq/#can-i-contribute-my-own-predictors-to-neuroscout","text":"Yes! Using the \"My Predictors\" function, you can create custom collections of predictors to add to your analyses. Simply navigate to My Predictors , and click on \"Add New Predictors\". Features should be in BIDS-compliant events format. Two columns are mandatory: \"onset\" and \"duration\" (both in seconds). You can then include any number of novel predictors as additional columns. Missing values can be annotated using the value \"n/a\" (no quotes). For each events file that you upload, you will be asked to associate it with runs in the respective dataset. Typically, there will be a different event file for each run in a naturalistic dataset. You must then associate each file with subjects. For example, in most cases, all subjects will have seen the same stimulus, but this will vary across datasets. After uploading, a new collection of predictors will be created. By default, predictors in this collection will be private, and only visible to you in the Analysis Builder. If you wish to share these predictors with other Neuroscout users, please contact us, and we can make your predictors public.","title":"Can I contribute my own predictors to Neuroscout?"},{"location":"browse/","text":"Browsing analyses Neuroscout lets you browse analyses you've created, as well as analyses that are publicly listed by other members of the community. To browse analyses, select My analyses or Public analyses under Browse in the navigation bar. Sort by any column by clicking on it. Editing analyses To launch the analysis builder, simply click the name of the analysis. Note that only analyses that are still in DRAFT mode (i.e. have not been submitted for bundle generation) are fully editable. However, you can launch the analysis in \"view-only\" mode for any analysis, including public ones. Remember that for your analyses, you can always change the name , description and public/private status. Note Instead of \"editing\" a PASSED analysis, you can use the clone feature to make an editable copy. Deleting analyses Similarly, only analyses that are still in DRAFT mode can be deleted. Simply click Delete in the right-most column. However, remember that you can always make an analysis private at any time.","title":"Browse"},{"location":"browse/#browsing-analyses","text":"Neuroscout lets you browse analyses you've created, as well as analyses that are publicly listed by other members of the community. To browse analyses, select My analyses or Public analyses under Browse in the navigation bar. Sort by any column by clicking on it.","title":"Browsing analyses"},{"location":"browse/#editing-analyses","text":"To launch the analysis builder, simply click the name of the analysis. Note that only analyses that are still in DRAFT mode (i.e. have not been submitted for bundle generation) are fully editable. However, you can launch the analysis in \"view-only\" mode for any analysis, including public ones. Remember that for your analyses, you can always change the name , description and public/private status. Note Instead of \"editing\" a PASSED analysis, you can use the clone feature to make an editable copy.","title":"Editing analyses"},{"location":"browse/#deleting-analyses","text":"Similarly, only analyses that are still in DRAFT mode can be deleted. Simply click Delete in the right-most column. However, remember that you can always make an analysis private at any time.","title":"Deleting analyses"},{"location":"browse/clone/","text":"Cloning analyses In Neuroscout you can only edit analyses that are still in DRAFT mode; that is, analyses that have not been submitted for, and passed, validation. Then, how can we make a similar analysis, or the same analysis in a different dataset, without starting from scratch? In Neuroscout , we can accomplish this using a \"clone and fork\" model. Think of this as using \"Save As\" in a word editor, instead of \"Save\". Simply click on the Clone button next to any PASSED analysis, in the analysis browser. Doing so, will create an exact copy of this analysis, with a new ID . This works exactly the same if you clone a public analysis, or an analysis you've previously created. Internally, it is recorded that this new analysis is based on an existing analysis, preserving the provenance of this model design. Editing cloned analyses Editing cloned analyses is no different from creating any other analysis. By clicking the name of the new analysis, you can launch the analysis builder. We recommend editing the name of this analysis to make it easier to differentiate from the previous one. Otherwise, proceed to edit and submit this analysis as usual. Changing datasets, keeping predictors What if you want to clone an existing analysis in order to run the same model on a different dataset? Simply select a new dataset from the list, and advance to the Predictors tab. Neuroscout will attempt to find the same predictors in this dataset, and pre-populate the list of selected predictors. If a given predictor cannot be found in this newly selected dataset, it will simply be removed from the model. Danger If a predictor cannot be found in a new dataset, and is removed from the model, all contrasts involving that predictor will also be removed.","title":"Clone"},{"location":"browse/clone/#cloning-analyses","text":"In Neuroscout you can only edit analyses that are still in DRAFT mode; that is, analyses that have not been submitted for, and passed, validation. Then, how can we make a similar analysis, or the same analysis in a different dataset, without starting from scratch? In Neuroscout , we can accomplish this using a \"clone and fork\" model. Think of this as using \"Save As\" in a word editor, instead of \"Save\". Simply click on the Clone button next to any PASSED analysis, in the analysis browser. Doing so, will create an exact copy of this analysis, with a new ID . This works exactly the same if you clone a public analysis, or an analysis you've previously created. Internally, it is recorded that this new analysis is based on an existing analysis, preserving the provenance of this model design.","title":"Cloning analyses"},{"location":"browse/clone/#editing-cloned-analyses","text":"Editing cloned analyses is no different from creating any other analysis. By clicking the name of the new analysis, you can launch the analysis builder. We recommend editing the name of this analysis to make it easier to differentiate from the previous one. Otherwise, proceed to edit and submit this analysis as usual.","title":"Editing cloned analyses"},{"location":"browse/clone/#changing-datasets-keeping-predictors","text":"What if you want to clone an existing analysis in order to run the same model on a different dataset? Simply select a new dataset from the list, and advance to the Predictors tab. Neuroscout will attempt to find the same predictors in this dataset, and pre-populate the list of selected predictors. If a given predictor cannot be found in this newly selected dataset, it will simply be removed from the model. Danger If a predictor cannot be found in a new dataset, and is removed from the model, all contrasts involving that predictor will also be removed.","title":"Changing datasets, keeping predictors"},{"location":"builder/","text":"Sign Up First things first, you need to register for an account on neuroscout.org . Currently, there are two supported options, the choice is yours! Create an account using an email address and password (old fashioned way). Use Google single sign on. If you create an account with us, you'll be asked to validate your email, as usual. Note Accounts are linked using email addresses. Signing up twice using the same email address, will result in a single account. Warning Note that Google accounts are currently not supported by the Neuroscout API wrapper pyNS . To interact with the API using pyNS, create an account using email and password. Once you've logged in, launch the analysis builder using the New Analysis navigation button. Overview In the analysis builder, you'll sequentially advance through tabs as you define your analysis. Later in the process, you can always go back to tabs that you've previously encountered, and make modifications. In the Overview tab, the first step is to give your analysis a name . This doesn't have to be a unique name (although that might be helpful), and you can always change it later. Optionally, also give your analysis a description . If you make many analyses, this could be very helpful. Choosing a dataset Neuroscout currently indexes a curated set of nine public naturalistic fMRI datasets. Datasets were specifically chosen for their compliance to the BIDS standard, and availability of original naturalistic stimuli. You can find detailed information on each dataset by clicking on the blue link icon. All datasets are minimally preprocessed using fmriprep 1.2.2 or greater, and ready for model fitting. If you have a dataset you'd like to contribute, see this frequently asked question . Selecting task and runs Once you've selected a dataset, you'll be able to choose which task and runs you want to analyze. Currently, we only support analyzing one task at a time. By default, all runs for that task are selected. If you want to select specific runs to analyze, either to only analyze a subset of subjects, or to omit certain runs that might have a known issue, you can use the run selector interface. Here you can browse and select specific runs. If you'd like to select groups of runs based on their BIDS entities (e.g. Subject , Run Number , etc..), click on the filter icon at the top of each column. A drop down menu will appear, allowing you to make a selection. Click \"OK\" to apply this filter. You can clear all filters and select all runs by clicking Clear Filters on the bottom left. Saving and unique ID To save your nascent analysis, click on the \"Save\" button. If the button is blue, that means there are unsaved changes. When you first save your analysis, it will be assigned a unique, permanent ID. Note that when you advance through tabs in the builder, the analysis will be automatically saved. Click on the Next button to advance to the Predictors selection tab.","title":"Getting started"},{"location":"builder/#sign-up","text":"First things first, you need to register for an account on neuroscout.org . Currently, there are two supported options, the choice is yours! Create an account using an email address and password (old fashioned way). Use Google single sign on. If you create an account with us, you'll be asked to validate your email, as usual. Note Accounts are linked using email addresses. Signing up twice using the same email address, will result in a single account. Warning Note that Google accounts are currently not supported by the Neuroscout API wrapper pyNS . To interact with the API using pyNS, create an account using email and password. Once you've logged in, launch the analysis builder using the New Analysis navigation button.","title":"Sign Up"},{"location":"builder/#overview","text":"In the analysis builder, you'll sequentially advance through tabs as you define your analysis. Later in the process, you can always go back to tabs that you've previously encountered, and make modifications. In the Overview tab, the first step is to give your analysis a name . This doesn't have to be a unique name (although that might be helpful), and you can always change it later. Optionally, also give your analysis a description . If you make many analyses, this could be very helpful.","title":"Overview"},{"location":"builder/#choosing-a-dataset","text":"Neuroscout currently indexes a curated set of nine public naturalistic fMRI datasets. Datasets were specifically chosen for their compliance to the BIDS standard, and availability of original naturalistic stimuli. You can find detailed information on each dataset by clicking on the blue link icon. All datasets are minimally preprocessed using fmriprep 1.2.2 or greater, and ready for model fitting. If you have a dataset you'd like to contribute, see this frequently asked question .","title":"Choosing a dataset"},{"location":"builder/#selecting-task-and-runs","text":"Once you've selected a dataset, you'll be able to choose which task and runs you want to analyze. Currently, we only support analyzing one task at a time. By default, all runs for that task are selected. If you want to select specific runs to analyze, either to only analyze a subset of subjects, or to omit certain runs that might have a known issue, you can use the run selector interface. Here you can browse and select specific runs. If you'd like to select groups of runs based on their BIDS entities (e.g. Subject , Run Number , etc..), click on the filter icon at the top of each column. A drop down menu will appear, allowing you to make a selection. Click \"OK\" to apply this filter. You can clear all filters and select all runs by clicking Clear Filters on the bottom left.","title":"Selecting task and runs"},{"location":"builder/#saving-and-unique-id","text":"To save your nascent analysis, click on the \"Save\" button. If the button is blue, that means there are unsaved changes. When you first save your analysis, it will be assigned a unique, permanent ID. Note that when you advance through tabs in the builder, the analysis will be automatically saved. Click on the Next button to advance to the Predictors selection tab.","title":"Saving and unique ID"},{"location":"builder/bib/","text":"Bibliography The bibliography tab will become available once an analysis has been submitted. Here, we summarize all the relevant references for the tools, data, and extractors used in an analysis. Be sure to cite these references if you publish any results stemming from this analysis. Export All If you wish to export these citations into a bibliography manager, we currently offer two formats: HTML - APA: An array of strings with APA formatted references. CSL - JSON: A complete specification of these reference in Citation Style Language . This format is importable into many reference managers, such as Mendeley.","title":"Bibliography"},{"location":"builder/bib/#bibliography","text":"The bibliography tab will become available once an analysis has been submitted. Here, we summarize all the relevant references for the tools, data, and extractors used in an analysis. Be sure to cite these references if you publish any results stemming from this analysis.","title":"Bibliography"},{"location":"builder/bib/#export-all","text":"If you wish to export these citations into a bibliography manager, we currently offer two formats: HTML - APA: An array of strings with APA formatted references. CSL - JSON: A complete specification of these reference in Citation Style Language . This format is importable into many reference managers, such as Mendeley.","title":"Export All"},{"location":"builder/contrasts/","text":"Contrasts In this tab, you can define contrasts to compute at the first-level after the design-matrix is fit to the fMRI activation time-course. As there are often no experimental conditions in naturalistic studies, it often makes the most sense to simply propagate the individual estimates for each predictor of interest (e.g. non-confounds). We can achieve this using \"dummy contrasts\", in which each Predictor is given a dummy-coded contrast of the same name. To do this for all non-confounds, simply click Generate Dummy Contrasts . Note If you go back to the Predictors tab and edit the predictor list, you may have to re-generate dummy contrasts. Defining a custom contrast To define a contrast, click Add Contrast . First, you must give the contrast a name. Next, select the predictors to include in this contrast. All predictors not selected will be given a weight of 0. Finally, enter the weights for the selected predictors. In this example, we are contrasting building and daylight using t contrast. As in the transformations tab, you can re-order, trash, and edit existing contrasts.","title":"Contrasts"},{"location":"builder/contrasts/#contrasts","text":"In this tab, you can define contrasts to compute at the first-level after the design-matrix is fit to the fMRI activation time-course. As there are often no experimental conditions in naturalistic studies, it often makes the most sense to simply propagate the individual estimates for each predictor of interest (e.g. non-confounds). We can achieve this using \"dummy contrasts\", in which each Predictor is given a dummy-coded contrast of the same name. To do this for all non-confounds, simply click Generate Dummy Contrasts . Note If you go back to the Predictors tab and edit the predictor list, you may have to re-generate dummy contrasts.","title":"Contrasts"},{"location":"builder/contrasts/#defining-a-custom-contrast","text":"To define a contrast, click Add Contrast . First, you must give the contrast a name. Next, select the predictors to include in this contrast. All predictors not selected will be given a weight of 0. Finally, enter the weights for the selected predictors. In this example, we are contrasting building and daylight using t contrast. As in the transformations tab, you can re-order, trash, and edit existing contrasts.","title":"Defining a custom contrast"},{"location":"builder/hrf/","text":"HRF Convolution In this tab, you can select which predictors you'd like to convolve with the canonical haemodynamic-response function (HRF). Typically, you'll want to convolve all non-confounds. You can easily do this by clicking Select All Non-Confounds . As in the Predictors tab, you can perform a full-text search over all the predictors you previously selected. For now, we are applying a \"SPM\" style HRF, with no derivatives. Note In reality, HRF convolution is another transformation that is applied after all other transformations.","title":"HRF Convolution"},{"location":"builder/hrf/#hrf-convolution","text":"In this tab, you can select which predictors you'd like to convolve with the canonical haemodynamic-response function (HRF). Typically, you'll want to convolve all non-confounds. You can easily do this by clicking Select All Non-Confounds . As in the Predictors tab, you can perform a full-text search over all the predictors you previously selected. For now, we are applying a \"SPM\" style HRF, with no derivatives. Note In reality, HRF convolution is another transformation that is applied after all other transformations.","title":"HRF Convolution"},{"location":"builder/predictors/","text":"Select Predictors In this tab, you can browse and search from hundreds of automatically extracted predictors to include in your model. Predictors each have a unique Name , and belong to a Source . They are also given a human readable Description . In the above example, we have selected the building predictor, that has the source ClarifaiAPIImageExtractor . This is an example of a predictor that was extracted from experimental stimuli. This predictor encodes the probability of a building in a given frame, according to the Clarifai Image Recognition API. You can use the search bar to filter predictors across all three columns. For example, here we searched for \"image recognition\", resulting in 67 matches. As you select predictors, they are displayed in the top right, helping you keep track of predictors not in the current search. You can click on the x on the right of each label to unselect that predictor. Note The predictor interface is your sole interface for adding predictors to the design matrix, including \"confounds\". Since all datasets are pre-processed with fmriprep , use that as a search term to display available confounds. In this example, we have already selected six fmriprep confounds to include in the model (6 rigid-body transforms, such as rot_x ). See the fmriprep documentation for in-depth information about these confound variables. Danger Very large models with dozens of predictors may be slow to compile and fit. We recommend starting with smaller models and building up to larger models as you've gained experience.","title":"Predictors"},{"location":"builder/predictors/#select-predictors","text":"In this tab, you can browse and search from hundreds of automatically extracted predictors to include in your model. Predictors each have a unique Name , and belong to a Source . They are also given a human readable Description . In the above example, we have selected the building predictor, that has the source ClarifaiAPIImageExtractor . This is an example of a predictor that was extracted from experimental stimuli. This predictor encodes the probability of a building in a given frame, according to the Clarifai Image Recognition API. You can use the search bar to filter predictors across all three columns. For example, here we searched for \"image recognition\", resulting in 67 matches. As you select predictors, they are displayed in the top right, helping you keep track of predictors not in the current search. You can click on the x on the right of each label to unselect that predictor. Note The predictor interface is your sole interface for adding predictors to the design matrix, including \"confounds\". Since all datasets are pre-processed with fmriprep , use that as a search term to display available confounds. In this example, we have already selected six fmriprep confounds to include in the model (6 rigid-body transforms, such as rot_x ). See the fmriprep documentation for in-depth information about these confound variables. Danger Very large models with dozens of predictors may be slow to compile and fit. We recommend starting with smaller models and building up to larger models as you've gained experience.","title":"Select Predictors"},{"location":"builder/review/","text":"Review Once you have selected predictors, applied transformations, and defined your contrasts, you're ready to review the statistical model you've designed. Design Report Upon reaching the Review tab, a report is requested from the Neuroscout server that will validate your analysis, apply transformations and pre-compute the design matrix to be fit to the fMRI data. It may take a few minutes to receive the report. Design Matrix Here you can interactively review the final design matrix that will be fit at the first-level of your analysis. The top plot will give you an overview of the design matrix, with each column of the design matrix on the x-axis and time on the y-axis. In the bottom plot, you can explore the predictor time courses in more detail. By clicking on the legend on the right, you can select specific predictors to plot. You may shift-click to select multiple predictors at once. Note For display purposes, each column is standardized prior to the creation of these plots, even if you did not request a scale transformation. This force re-scaling will not be performed when creating the actual design matrix. Correlation Matrix The correlation matrix provides you an opportunity to review the covariance between your predictors. Note that predictors that are highly correlated with each other may result in a rank deficient design matrix which will cause model fitting to fail. Hint Hover over values in the plot to see the correlation r-values. Analysis Overview Finally, a complete summary of your analysis is displayed in this tab. Here you can review all of the choices you've made and ensure you are happy with the analysis prior to continuing. Note Neuroscout stores your model design using BIDS Stats-Model, an in-development JSON standard for representing fMRI models. This is the true, final representation of your model, so if you are having problems, or would like to meticulously review your analysis, review this section.","title":"Review"},{"location":"builder/review/#review","text":"Once you have selected predictors, applied transformations, and defined your contrasts, you're ready to review the statistical model you've designed.","title":"Review"},{"location":"builder/review/#design-report","text":"Upon reaching the Review tab, a report is requested from the Neuroscout server that will validate your analysis, apply transformations and pre-compute the design matrix to be fit to the fMRI data. It may take a few minutes to receive the report.","title":"Design Report"},{"location":"builder/review/#design-matrix","text":"Here you can interactively review the final design matrix that will be fit at the first-level of your analysis. The top plot will give you an overview of the design matrix, with each column of the design matrix on the x-axis and time on the y-axis. In the bottom plot, you can explore the predictor time courses in more detail. By clicking on the legend on the right, you can select specific predictors to plot. You may shift-click to select multiple predictors at once. Note For display purposes, each column is standardized prior to the creation of these plots, even if you did not request a scale transformation. This force re-scaling will not be performed when creating the actual design matrix.","title":"Design Matrix"},{"location":"builder/review/#correlation-matrix","text":"The correlation matrix provides you an opportunity to review the covariance between your predictors. Note that predictors that are highly correlated with each other may result in a rank deficient design matrix which will cause model fitting to fail. Hint Hover over values in the plot to see the correlation r-values.","title":"Correlation Matrix"},{"location":"builder/review/#analysis-overview","text":"Finally, a complete summary of your analysis is displayed in this tab. Here you can review all of the choices you've made and ensure you are happy with the analysis prior to continuing. Note Neuroscout stores your model design using BIDS Stats-Model, an in-development JSON standard for representing fMRI models. This is the true, final representation of your model, so if you are having problems, or would like to meticulously review your analysis, review this section.","title":"Analysis Overview"},{"location":"builder/run/","text":"Analysis Bundle Generation After you've reviewed your analysis, you need to generate an executable analysis bundle prior to being able to execute it. In the upper right you'll find a toggle that let's you switch from a public analysis (the default), to private. Public analyses are listed under \"public analyses\", and are searchable by other Neuroscout users. Private analyses do not show up in this listing, but be aware that any user with the analyses' unique ID can view this analysis. You can use this to your advantage to share your analysis with your colleagues. If you agree to the terms, click Generate to submit. Be patient, analysis bundle generation may take a while. If you're in a rush, and are willing to risk additional run-time errors, uncheck Validate design matrix . After submission After submitting your analysis, it will no longer be editable unless there is an error in your design that you must fix. If your analysis successfully compiles, an example neuroscout-cli command will be shown. For more information on how to execute an analysis, head over to the Run analysis section. Note After your analysis is compiled, you can change the public/private settings of your analysis, as well as edit the name and description . Also, notice the Review tab is still available.","title":"Run / Status"},{"location":"builder/run/#analysis-bundle-generation","text":"After you've reviewed your analysis, you need to generate an executable analysis bundle prior to being able to execute it. In the upper right you'll find a toggle that let's you switch from a public analysis (the default), to private. Public analyses are listed under \"public analyses\", and are searchable by other Neuroscout users. Private analyses do not show up in this listing, but be aware that any user with the analyses' unique ID can view this analysis. You can use this to your advantage to share your analysis with your colleagues. If you agree to the terms, click Generate to submit. Be patient, analysis bundle generation may take a while. If you're in a rush, and are willing to risk additional run-time errors, uncheck Validate design matrix .","title":"Analysis Bundle Generation"},{"location":"builder/run/#after-submission","text":"After submitting your analysis, it will no longer be editable unless there is an error in your design that you must fix. If your analysis successfully compiles, an example neuroscout-cli command will be shown. For more information on how to execute an analysis, head over to the Run analysis section. Note After your analysis is compiled, you can change the public/private settings of your analysis, as well as edit the name and description . Also, notice the Review tab is still available.","title":"After submission"},{"location":"builder/transformations/","text":"Add Transformations The next step in defining a model is to transform the variables you've selected. This step is optional-- for many models you may not need to make any modifications to the input variables. To add a transformation, click Add Transformation and select an operation from the drop-down list. The transformations currently supported by Neuroscout are a subset of the complete set of transformations detailed in the BIDS StatsModel specification (in active development). As Neuroscout matures, the number of supported transformations will grow. Transformation Description Scale Standardize the value of one or more variables. Can independently choose to demean and/or rescale. Orthogonalize Orthogonalizes one or more input columns with respect to one or more other columns. Select input For all transformation, you must select which features this transformation will operate on. Most operations will operate on each column independently, but specifying multiple columns will save you from having to specify the same operation for multiple predictors. Transformation-specific options Most transformations additionally have specific options which you can specify. Scale Demean - If True, subtracts the mean from each input column (i.e., applies mean-centering). Rescale - If True, divides each column by its standard deviation. ReplaceNA - Whether/when to replace missing values with 0. \"Don't replace\"- no replacement is performed. If 'before', missing values are replaced with 0's before scaling. If 'after', missing values are replaced with 0 after scaling. Orthogonalize You must select the inputs to orthogonalize with respect to. The transformed variable will be uncorrelated to these variables. Threshold Threshold - The value to binarize around (values above will be assigned 1, values below will be assigned 0) Binarize - If True, binarizes all non-zero values (i.e., every non-zero value will be set to 1). Above - Specifies which values to retain with respect to the cut-off. If True, all values above the threshold will be kept; if False, all values below the threshold will be kept. Signed - Specifies whether to treat the threshold as signed (default) or unsigned. For example, when passing above=True and threshold=3, if signed=True, all and only values above +3 would be retained. If signed=False, all absolute values > 3 would be retained (i.e.,values in the range -3 < X < 3 would be set to 0). Editing and order It is important to note that transformations are applied sequentially, so the order of the transformation matters. To re-order transformations you can drag and drop them in the list. You can also remove transformations you've created using the trash icon, and edit existing transformations with the blue edit icon.","title":"Transformations"},{"location":"builder/transformations/#add-transformations","text":"The next step in defining a model is to transform the variables you've selected. This step is optional-- for many models you may not need to make any modifications to the input variables. To add a transformation, click Add Transformation and select an operation from the drop-down list. The transformations currently supported by Neuroscout are a subset of the complete set of transformations detailed in the BIDS StatsModel specification (in active development). As Neuroscout matures, the number of supported transformations will grow. Transformation Description Scale Standardize the value of one or more variables. Can independently choose to demean and/or rescale. Orthogonalize Orthogonalizes one or more input columns with respect to one or more other columns.","title":"Add Transformations"},{"location":"builder/transformations/#select-input","text":"For all transformation, you must select which features this transformation will operate on. Most operations will operate on each column independently, but specifying multiple columns will save you from having to specify the same operation for multiple predictors.","title":"Select input"},{"location":"builder/transformations/#transformation-specific-options","text":"Most transformations additionally have specific options which you can specify.","title":"Transformation-specific options"},{"location":"builder/transformations/#scale","text":"Demean - If True, subtracts the mean from each input column (i.e., applies mean-centering). Rescale - If True, divides each column by its standard deviation. ReplaceNA - Whether/when to replace missing values with 0. \"Don't replace\"- no replacement is performed. If 'before', missing values are replaced with 0's before scaling. If 'after', missing values are replaced with 0 after scaling.","title":"Scale"},{"location":"builder/transformations/#orthogonalize","text":"You must select the inputs to orthogonalize with respect to. The transformed variable will be uncorrelated to these variables.","title":"Orthogonalize"},{"location":"builder/transformations/#threshold","text":"Threshold - The value to binarize around (values above will be assigned 1, values below will be assigned 0) Binarize - If True, binarizes all non-zero values (i.e., every non-zero value will be set to 1). Above - Specifies which values to retain with respect to the cut-off. If True, all values above the threshold will be kept; if False, all values below the threshold will be kept. Signed - Specifies whether to treat the threshold as signed (default) or unsigned. For example, when passing above=True and threshold=3, if signed=True, all and only values above +3 would be retained. If signed=False, all absolute values > 3 would be retained (i.e.,values in the range -3 < X < 3 would be set to 0).","title":"Threshold"},{"location":"builder/transformations/#editing-and-order","text":"It is important to note that transformations are applied sequentially, so the order of the transformation matters. To re-order transformations you can drag and drop them in the list. You can also remove transformations you've created using the trash icon, and edit existing transformations with the blue edit icon.","title":"Editing and order"},{"location":"cli/","text":"Neuroscout-cli The Neuroscout Command Line Interface ( neuroscout-cli ) allows you to execute analyses created on neuroscout.org . neuroscout-cli makes it easy to run your analysis with no configuration by fetching a self-contained analysis bundle, and downloading the required preprocessed fMRI data using DataLad . neuroscout-cli internally uses FitLins , a python pipeline for fMRI analysis in BIDS, to fit a statistical model to the fMRI data, and produce comprehensive reports. neuroscout-cli automatically uploads the resulting images to Neurovault , and links them to the analysis listing, making it easy to view and share your results. Installation & Usage The recommended way to install and use neuroscout-cli is using containers (i.e. Docker or Singularity). Containers greatly facilitate the management of software dependencies, and increase reproducibility of results. You can also install neuroscout-cli directly on your system using a manually prepared environment, although this typically requires more effort. A third method of running analyses is Google Colab, though larger analyses will take longer to run using the limited free resources. Containerized Execution Docker For most systems, we recommend using Docker . First, follow the instructions for installing Docker on your system. Next, follow our guide for running Neuroscout on Docker Singularity Singularity containers are a great solution for High Performance Computing (HPC) environments, where Docker cannot typically be used due to more tightly controlled user privileges . First, check with your HPC administrator that Singularity is available for use. If so, follow our guide for running Neuroscout on Singularity . Google Colab A Google colab notebook is available here where you can run a sample pre-generated analysis with an already provided id or provide your own analysis id. To run your own analysis, copy your id into the field in the cell labelled 1) Set Neuroscout Analysis ID and then run all of the cells. The provided id will run 10 subjects and 1 run from the Budapest dataset, and may take around 15 minutes. Larger analyses will take longer due to the limited free resources. Manually prepared environment Danger Manually installing neuroscout-cli can be difficult due to complex dependencies. Proceed only if you really need to do this. Use pip to install neuroscout-cli directly from the GitHub repo: pip install git+https://www.github.com/neuroscout/neuroscout-cli","title":"Introduction"},{"location":"cli/#neuroscout-cli","text":"The Neuroscout Command Line Interface ( neuroscout-cli ) allows you to execute analyses created on neuroscout.org . neuroscout-cli makes it easy to run your analysis with no configuration by fetching a self-contained analysis bundle, and downloading the required preprocessed fMRI data using DataLad . neuroscout-cli internally uses FitLins , a python pipeline for fMRI analysis in BIDS, to fit a statistical model to the fMRI data, and produce comprehensive reports. neuroscout-cli automatically uploads the resulting images to Neurovault , and links them to the analysis listing, making it easy to view and share your results.","title":"Neuroscout-cli"},{"location":"cli/#installation-usage","text":"The recommended way to install and use neuroscout-cli is using containers (i.e. Docker or Singularity). Containers greatly facilitate the management of software dependencies, and increase reproducibility of results. You can also install neuroscout-cli directly on your system using a manually prepared environment, although this typically requires more effort. A third method of running analyses is Google Colab, though larger analyses will take longer to run using the limited free resources.","title":"Installation &amp; Usage"},{"location":"cli/#containerized-execution","text":"","title":"Containerized Execution"},{"location":"cli/#docker","text":"For most systems, we recommend using Docker . First, follow the instructions for installing Docker on your system. Next, follow our guide for running Neuroscout on Docker","title":"Docker"},{"location":"cli/#singularity","text":"Singularity containers are a great solution for High Performance Computing (HPC) environments, where Docker cannot typically be used due to more tightly controlled user privileges . First, check with your HPC administrator that Singularity is available for use. If so, follow our guide for running Neuroscout on Singularity .","title":"Singularity"},{"location":"cli/#google-colab","text":"A Google colab notebook is available here where you can run a sample pre-generated analysis with an already provided id or provide your own analysis id. To run your own analysis, copy your id into the field in the cell labelled 1) Set Neuroscout Analysis ID and then run all of the cells. The provided id will run 10 subjects and 1 run from the Budapest dataset, and may take around 15 minutes. Larger analyses will take longer due to the limited free resources.","title":"Google Colab"},{"location":"cli/#manually-prepared-environment","text":"Danger Manually installing neuroscout-cli can be difficult due to complex dependencies. Proceed only if you really need to do this. Use pip to install neuroscout-cli directly from the GitHub repo: pip install git+https://www.github.com/neuroscout/neuroscout-cli","title":"Manually prepared environment"},{"location":"cli/colab/","text":"Running Neuroscout-CLI on Google Colab A Google colab notebook is available here where you can run a sample pre-generated analysis with an already provided id or provide your own analysis id. To run your own analysis, copy your id into the field in the cell labelled 1) Set Neuroscout Analysis ID and then run all of the cells. The provided id will run 10 subjects and 1 run from the Budapest dataset, and may take around 15 minutes. Larger analyses will take longer due to the limited free resources.","title":"Google Colab"},{"location":"cli/colab/#running-neuroscout-cli-on-google-colab","text":"A Google colab notebook is available here where you can run a sample pre-generated analysis with an already provided id or provide your own analysis id. To run your own analysis, copy your id into the field in the cell labelled 1) Set Neuroscout Analysis ID and then run all of the cells. The provided id will run 10 subjects and 1 run from the Budapest dataset, and may take around 15 minutes. Larger analyses will take longer due to the limited free resources.","title":"Running Neuroscout-CLI on Google Colab"},{"location":"cli/docker/","text":"Running Neuroscout-CLI on Docker Quickstart Note You must have Docker installed on your system Assuming you've already created an analysis on neuroscout.org, you can run it in one line using the analysis_id (e.g.: a54oo ): docker run -it -v /local/dir:/outdir neuroscout/neuroscout-cli run 5xH93 /outdir where /local/dir is the local directory you want to save the results. This command will first download the latest stable release of neuroscout-cli . Next, neuroscout-cli will download the corresponding preprocessed images, event files and model specification, and fit a multi-level GLM model. The results will be automatically uploaded to NeuroVault, and the analysis page will link to this upload: https://neuroscout.org/builder/a54oo. -it --rm simply tells Docker to run in interactive mode and remove the running container after execution. See the following sections for how to customize this command to cache the downloaded data for future use, and save modeling outputs to disk. Docker Images For every release of neuroscout-cli , we publish a corresponding Docker image You can manually download a specific neuroscout-cli release as follows: docker pull neuroscout/neuroscout-cli:<version> where <version> is the version of neuroscout-cli that you want to download. If you omit version, the latest stable version will be downloaded. You can see the tags available for download on Docker Hub . You can also reference a <version> in the run command. For example: docker run -it --rm neuroscout/neuroscout-cli:version-0.5.1 run Mv3ev /out Note master is a special tag name which refers to the most recent unstable commit to GitHub. Saving outputs to disk Containers are by default sandboxed so that they have access to a clean and separate environment. To access files in the container, you must explicitly mount volumes from your system to the Docker container. You can mount local directories to Docker containers using the -v argument, with the following syntax: /local/host/path:/absolute/path/in/container . Here we mount the local /home/user/out directory to /out on the container.: docker run -it --rm -v /home/user/out:/out neuroscout/neuroscout-cli run 5xH93 /out Note After the run command, we are telling neuroscout-cli to save the outputs to the /out directory on Docker , which is mapped to /home/user/out on our local system. Output derivative structure Neuroscout creates a unique output directory neuroscout-{analysis_id} for each analysis. Given the analysis_id : Mv3ev and dataset_name : Budapest , this is a representative directory structure: /home/user/out/neuroscout-Mv3ev \u2514\u2500\u2500\u2500sourcedata \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Budapest \u2502 \u2514\u2500\u2500\u2500fmriprep \u2502 \u2514\u2500\u2500\u2500bundle \u2502 \u2514\u2500\u2500\u2500events \u2502 \u2502 model.json \u2502 \u2502 ... \u2514\u2500\u2500\u2500fitlins \u2502 \u2514\u2500\u2500\u2500sub-01 \u2502 \u2514\u2500\u2500\u2500reports \u2502 \u2502 task-movie_space-MNI152NLin2009cAsym_contrast-{name}_stat-effect_statmap.nii.gz | | ... Note that by default Neuroscout will save the input preprocessed fMRI images in the output folder, to create a fully reproducible result package. Caching input datasets If you plan to run more than one analysis per dataset, it's wise to download the input fMRI data to a directory available to multiple analyses. To do so simply specify a data directory with --download-dir , and mount the corresponding local directory. docker run -it --rm -v /home/user/out:/out -v /home/user/data:/data neuroscout/neuroscout-cli --download-dir=/data run Mv3ev /out The resulting cached data directory will look something like this, if you've run several analyses from different datasets: /home/user/data \u2514\u2500\u2500\u2500Budapest \u2502 \u2514\u2500\u2500\u2500fmriprep \u2514\u2500\u2500\u2500studyforrest \u2502 \u2514\u2500\u2500\u2500fmriprep The next time you run a model with a previously downloaded dataset, it will not need to re-download the fMRI data. Important Docker expects absolute paths for mounted directories Other command line arguments neuroscout-cli has many more command line arguments which can be specified at the end: docker run -it --rm neuroscout/neuroscout-cli run /out Mv3ev <args> For example, if you wanted to specify the estimator to be AFNI instead of nilearn , and the number of CPU's to be 15 : docker run -it --rm neuroscout/neuroscout-cli run /out Mv3ev --n-cpus=15 --estimator=afni For more details on these arguments, see this reference .","title":"Docker"},{"location":"cli/docker/#running-neuroscout-cli-on-docker","text":"","title":"Running Neuroscout-CLI on Docker"},{"location":"cli/docker/#quickstart","text":"Note You must have Docker installed on your system Assuming you've already created an analysis on neuroscout.org, you can run it in one line using the analysis_id (e.g.: a54oo ): docker run -it -v /local/dir:/outdir neuroscout/neuroscout-cli run 5xH93 /outdir where /local/dir is the local directory you want to save the results. This command will first download the latest stable release of neuroscout-cli . Next, neuroscout-cli will download the corresponding preprocessed images, event files and model specification, and fit a multi-level GLM model. The results will be automatically uploaded to NeuroVault, and the analysis page will link to this upload: https://neuroscout.org/builder/a54oo. -it --rm simply tells Docker to run in interactive mode and remove the running container after execution. See the following sections for how to customize this command to cache the downloaded data for future use, and save modeling outputs to disk.","title":"Quickstart"},{"location":"cli/docker/#docker-images","text":"For every release of neuroscout-cli , we publish a corresponding Docker image You can manually download a specific neuroscout-cli release as follows: docker pull neuroscout/neuroscout-cli:<version> where <version> is the version of neuroscout-cli that you want to download. If you omit version, the latest stable version will be downloaded. You can see the tags available for download on Docker Hub . You can also reference a <version> in the run command. For example: docker run -it --rm neuroscout/neuroscout-cli:version-0.5.1 run Mv3ev /out Note master is a special tag name which refers to the most recent unstable commit to GitHub.","title":"Docker Images"},{"location":"cli/docker/#saving-outputs-to-disk","text":"Containers are by default sandboxed so that they have access to a clean and separate environment. To access files in the container, you must explicitly mount volumes from your system to the Docker container. You can mount local directories to Docker containers using the -v argument, with the following syntax: /local/host/path:/absolute/path/in/container . Here we mount the local /home/user/out directory to /out on the container.: docker run -it --rm -v /home/user/out:/out neuroscout/neuroscout-cli run 5xH93 /out Note After the run command, we are telling neuroscout-cli to save the outputs to the /out directory on Docker , which is mapped to /home/user/out on our local system.","title":"Saving outputs to disk"},{"location":"cli/docker/#output-derivative-structure","text":"Neuroscout creates a unique output directory neuroscout-{analysis_id} for each analysis. Given the analysis_id : Mv3ev and dataset_name : Budapest , this is a representative directory structure: /home/user/out/neuroscout-Mv3ev \u2514\u2500\u2500\u2500sourcedata \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Budapest \u2502 \u2514\u2500\u2500\u2500fmriprep \u2502 \u2514\u2500\u2500\u2500bundle \u2502 \u2514\u2500\u2500\u2500events \u2502 \u2502 model.json \u2502 \u2502 ... \u2514\u2500\u2500\u2500fitlins \u2502 \u2514\u2500\u2500\u2500sub-01 \u2502 \u2514\u2500\u2500\u2500reports \u2502 \u2502 task-movie_space-MNI152NLin2009cAsym_contrast-{name}_stat-effect_statmap.nii.gz | | ... Note that by default Neuroscout will save the input preprocessed fMRI images in the output folder, to create a fully reproducible result package.","title":"Output derivative structure"},{"location":"cli/docker/#caching-input-datasets","text":"If you plan to run more than one analysis per dataset, it's wise to download the input fMRI data to a directory available to multiple analyses. To do so simply specify a data directory with --download-dir , and mount the corresponding local directory. docker run -it --rm -v /home/user/out:/out -v /home/user/data:/data neuroscout/neuroscout-cli --download-dir=/data run Mv3ev /out The resulting cached data directory will look something like this, if you've run several analyses from different datasets: /home/user/data \u2514\u2500\u2500\u2500Budapest \u2502 \u2514\u2500\u2500\u2500fmriprep \u2514\u2500\u2500\u2500studyforrest \u2502 \u2514\u2500\u2500\u2500fmriprep The next time you run a model with a previously downloaded dataset, it will not need to re-download the fMRI data. Important Docker expects absolute paths for mounted directories","title":"Caching input datasets"},{"location":"cli/docker/#other-command-line-arguments","text":"neuroscout-cli has many more command line arguments which can be specified at the end: docker run -it --rm neuroscout/neuroscout-cli run /out Mv3ev <args> For example, if you wanted to specify the estimator to be AFNI instead of nilearn , and the number of CPU's to be 15 : docker run -it --rm neuroscout/neuroscout-cli run /out Mv3ev --n-cpus=15 --estimator=afni For more details on these arguments, see this reference .","title":"Other command line arguments"},{"location":"cli/singularity/","text":"Running Neuroscout-CLI on Singularity (High Performance Clusters) Note Singularity must be available on your HPC. Contact your administrator. This guide is for Singularity >= 2.5. Important HPCs typically require jobs to be submitted using a scheduled such as SLURM. This will not be covered in this guide, and will assume commands are run on compute nodes (via interactive sessions or submitted scripts) Preparing Singularity Images. Unlike Docker , you must explicitly download or compile Singularity images to a file prior to execution. For every release of neuroscout-cli , we publish Singularity images to GitHub Packages which mirror the images published on Docker Hub. You can download the latest pre-compiled image as follows: singularity pull oras://ghcr.io/neuroscout/neuroscout-cli:<version> where <version> is the version of neuroscout-cli that you want to download. You must specify a version. You can see the tags available for download on GitHub Packages . Note master is a special tag name which refers to the most recent unstable commit to GitHub. latest refers to the latest stable release. Executing Singularity image Assuming you've already created an analysis on neuroscout.org , and have its analysis id (e.g.: Mv3ev ), you can run it in one line: singularity run --cleanenv neuroscout-cli-<version>.simg Mv3ev <outdir> Where <outdir> is a directory you can save files to. This command will download the corresponding preprocessed images, event files and model specification, and fit a multi-level GLM model. The results will be automatically uploaded to NeuroVault, and the analysis page will link to this upload: https://neuroscout.org/builder/Mv3ev. Important neuroscout-cli-<version>.simg refers to a specific downloaded image on your system. Saving data to disk Singularity typically automatically mounts host volumes to the container. This may differ between systems, so see the documentation for your HPC for more details. Thus, you can simplify modify <outdir> to a directory of your choice: singularity run --cleanenv neuroscout-cli-<version>.simg run /work/dir/out Mv3ev See here for more details on the output directory structure. Caching input datasets If you wish to save the input preprocessed datasets elsewhere, simply specify a data installation directory with --download-dir L singularity run --cleanenv neuroscout-cli-<version>.simg run --download-dir=/data Mv3ev /work/dir/out See here for more details on the cached data structure. For further guidance, see our usage reference guide. for more details on the cached data structure.","title":"Singularity"},{"location":"cli/singularity/#running-neuroscout-cli-on-singularity-high-performance-clusters","text":"Note Singularity must be available on your HPC. Contact your administrator. This guide is for Singularity >= 2.5. Important HPCs typically require jobs to be submitted using a scheduled such as SLURM. This will not be covered in this guide, and will assume commands are run on compute nodes (via interactive sessions or submitted scripts)","title":"Running Neuroscout-CLI on Singularity (High Performance Clusters)"},{"location":"cli/singularity/#preparing-singularity-images","text":"Unlike Docker , you must explicitly download or compile Singularity images to a file prior to execution. For every release of neuroscout-cli , we publish Singularity images to GitHub Packages which mirror the images published on Docker Hub. You can download the latest pre-compiled image as follows: singularity pull oras://ghcr.io/neuroscout/neuroscout-cli:<version> where <version> is the version of neuroscout-cli that you want to download. You must specify a version. You can see the tags available for download on GitHub Packages . Note master is a special tag name which refers to the most recent unstable commit to GitHub. latest refers to the latest stable release.","title":"Preparing Singularity Images."},{"location":"cli/singularity/#executing-singularity-image","text":"Assuming you've already created an analysis on neuroscout.org , and have its analysis id (e.g.: Mv3ev ), you can run it in one line: singularity run --cleanenv neuroscout-cli-<version>.simg Mv3ev <outdir> Where <outdir> is a directory you can save files to. This command will download the corresponding preprocessed images, event files and model specification, and fit a multi-level GLM model. The results will be automatically uploaded to NeuroVault, and the analysis page will link to this upload: https://neuroscout.org/builder/Mv3ev. Important neuroscout-cli-<version>.simg refers to a specific downloaded image on your system.","title":"Executing Singularity image"},{"location":"cli/singularity/#saving-data-to-disk","text":"Singularity typically automatically mounts host volumes to the container. This may differ between systems, so see the documentation for your HPC for more details. Thus, you can simplify modify <outdir> to a directory of your choice: singularity run --cleanenv neuroscout-cli-<version>.simg run /work/dir/out Mv3ev See here for more details on the output directory structure.","title":"Saving data to disk"},{"location":"cli/singularity/#caching-input-datasets","text":"If you wish to save the input preprocessed datasets elsewhere, simply specify a data installation directory with --download-dir L singularity run --cleanenv neuroscout-cli-<version>.simg run --download-dir=/data Mv3ev /work/dir/out See here for more details on the cached data structure. For further guidance, see our usage reference guide. for more details on the cached data structure.","title":"Caching input datasets"},{"location":"cli/usage/","text":"Neuroscout-CLI Usage Note If you're just starting out, we suggest you follow our Docker quickstart . Remember that if you're using Docker or Singularity, you will have to prepend the following commands with the respective container commands (e.g. docker run -it neuroscout/neuroscout-cli ), and mount the appropriate volumes. Neuroscout-CLI commands Neuroscout-CLI has three commands: run , get and upload . By default, run will automatically use get to fetch the required inputs, and automatically upload results after execution. Thus, in most cases, the run command is all you need. Let's step through each command: Run Usage: neuroscout run [OPTIONS] [FITLINS_OPTIONS]... ANALYSIS_ID OUT_DIR Run an analysis. Automatically gets inputs and uploads results to NeuroVault by default. This command uses FitLins for execution. Thus, any valid options can be passed through in [FITLINS_OPTIONS]. Note: `--model`, `--derivatives` and `--ignore` and positional arguments are automatically configured. Example: neuroscout run --force-upload --n-cpus=3 a54oo /out If using Docker, remember to map local volumes to save outputs: docker run --rm -it -v /local/dir:/out neuroscout/neuroscout-cli run a54oo /out Options: --download-dir PATH Directory to cache input datasets, instead of OUT_DIR --no-get Don't automatically fetch bundle & dataset --force-upload Force upload even if a NV collection already exists --no-upload Don't upload results to NeuroVault --upload-first-level Upload first-level results, in addition to group --fitlins-help Display FitLins help and options --help Show this message and exit. The run command will first call get to download the necessary data. Next, run will call FitLins for execution. As noted, you may pass any valid options to FitLins at runtime. To see which options are available in FitLins, use --fitlins-help . Note that certain arguments to FitLins are automatically pre-set, as they are required by Neuroscout. After FitLins completes, run will automatically upload the results using the upload command. See each command below for more detail on downloading inputs, and uploading results. Get Usage: neuroscout get [OPTIONS] ANALYSIS_ID OUT_DIR Fetch analysis inputs. Downloads the analysis bundle, preprocessed fMRI inputs, and configures output directory. Inputs are downloaded to the output directory under `sourcedata`. If you run many analyses, you may wish to provide an `--download-dir` where datasets can be cached across analyses. Note: `run` automatically calls `get` prior to execution, by default. Options: --download-dir PATH Directory to cache input datasets, instead of OUT_DIR --bundle-only Only fetch analysis bundle, not imaging data --help Show this message and exit. The get command prepares your system for analysis execution by 1) preparing the output directory, 2) downloading the analysis bundle (containing the BIDS StatsModel specification, event files, and more), and 3) downloading the preprocessed fMRI data. Note that only the specific files for that analysis will be download (i.e. only those runs/subjects) By default, the input fMRI data is downloaded to the output directory under sourcedata , forming a fully re-executable output. However, if you run many analyses with the same dataset, it can be useful to download the data to a common folder that can be re-used in other analyses using --download-dir For example: neuroscout get --download-dir /home/user/data a54oo /home/user/outputs In this case, the fMRI dataset will be downloaded to /home/user/data and the output folder will be /home/user/outputs/neuroscout-a54oo , with the bundle contents saved in the output folder. Note If you use the get command with --download-dir , be sure to also specify this directory when calling run , otherwise the data will be re-downloaded to the output directory. Upload Usage: neuroscout upload [OPTIONS] ANALYSIS_ID OUT_DIR Upload results. This command can be used to upload existing results to NeuroVault. Note: `run` automatically calls `upload` after execution, by default. Options: --force-upload Force upload even if a NV collection already exists --no-upload Don't upload results to NeuroVault --upload-first-level Upload first-level results, in addition to group --help Show this message and exit. The upload command may be useful in case the run command experienced an error uploading results, particularly if there was a connection error, and you wish to try again. Otherwise, it's typically reccomended to let the run command automatically upload results.","title":"General Usage"},{"location":"cli/usage/#neuroscout-cli-usage","text":"Note If you're just starting out, we suggest you follow our Docker quickstart . Remember that if you're using Docker or Singularity, you will have to prepend the following commands with the respective container commands (e.g. docker run -it neuroscout/neuroscout-cli ), and mount the appropriate volumes.","title":"Neuroscout-CLI Usage"},{"location":"cli/usage/#neuroscout-cli-commands","text":"Neuroscout-CLI has three commands: run , get and upload . By default, run will automatically use get to fetch the required inputs, and automatically upload results after execution. Thus, in most cases, the run command is all you need. Let's step through each command:","title":"Neuroscout-CLI commands"},{"location":"cli/usage/#run","text":"Usage: neuroscout run [OPTIONS] [FITLINS_OPTIONS]... ANALYSIS_ID OUT_DIR Run an analysis. Automatically gets inputs and uploads results to NeuroVault by default. This command uses FitLins for execution. Thus, any valid options can be passed through in [FITLINS_OPTIONS]. Note: `--model`, `--derivatives` and `--ignore` and positional arguments are automatically configured. Example: neuroscout run --force-upload --n-cpus=3 a54oo /out If using Docker, remember to map local volumes to save outputs: docker run --rm -it -v /local/dir:/out neuroscout/neuroscout-cli run a54oo /out Options: --download-dir PATH Directory to cache input datasets, instead of OUT_DIR --no-get Don't automatically fetch bundle & dataset --force-upload Force upload even if a NV collection already exists --no-upload Don't upload results to NeuroVault --upload-first-level Upload first-level results, in addition to group --fitlins-help Display FitLins help and options --help Show this message and exit. The run command will first call get to download the necessary data. Next, run will call FitLins for execution. As noted, you may pass any valid options to FitLins at runtime. To see which options are available in FitLins, use --fitlins-help . Note that certain arguments to FitLins are automatically pre-set, as they are required by Neuroscout. After FitLins completes, run will automatically upload the results using the upload command. See each command below for more detail on downloading inputs, and uploading results.","title":"Run"},{"location":"cli/usage/#get","text":"Usage: neuroscout get [OPTIONS] ANALYSIS_ID OUT_DIR Fetch analysis inputs. Downloads the analysis bundle, preprocessed fMRI inputs, and configures output directory. Inputs are downloaded to the output directory under `sourcedata`. If you run many analyses, you may wish to provide an `--download-dir` where datasets can be cached across analyses. Note: `run` automatically calls `get` prior to execution, by default. Options: --download-dir PATH Directory to cache input datasets, instead of OUT_DIR --bundle-only Only fetch analysis bundle, not imaging data --help Show this message and exit. The get command prepares your system for analysis execution by 1) preparing the output directory, 2) downloading the analysis bundle (containing the BIDS StatsModel specification, event files, and more), and 3) downloading the preprocessed fMRI data. Note that only the specific files for that analysis will be download (i.e. only those runs/subjects) By default, the input fMRI data is downloaded to the output directory under sourcedata , forming a fully re-executable output. However, if you run many analyses with the same dataset, it can be useful to download the data to a common folder that can be re-used in other analyses using --download-dir For example: neuroscout get --download-dir /home/user/data a54oo /home/user/outputs In this case, the fMRI dataset will be downloaded to /home/user/data and the output folder will be /home/user/outputs/neuroscout-a54oo , with the bundle contents saved in the output folder. Note If you use the get command with --download-dir , be sure to also specify this directory when calling run , otherwise the data will be re-downloaded to the output directory.","title":"Get"},{"location":"cli/usage/#upload","text":"Usage: neuroscout upload [OPTIONS] ANALYSIS_ID OUT_DIR Upload results. This command can be used to upload existing results to NeuroVault. Note: `run` automatically calls `upload` after execution, by default. Options: --force-upload Force upload even if a NV collection already exists --no-upload Don't upload results to NeuroVault --upload-first-level Upload first-level results, in addition to group --help Show this message and exit. The upload command may be useful in case the run command experienced an error uploading results, particularly if there was a connection error, and you wish to try again. Otherwise, it's typically reccomended to let the run command automatically upload results.","title":"Upload"}]}